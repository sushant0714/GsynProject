# GsynProject

<p>
This project involves processing data in Databricks by mounting an Azure Data Lake Storage (ADLS) account and executing a main script with essential checks. The workflow ensures that all dependencies and data sources are properly set up before running the main logic.

Prerequisites

Before running the project, ensure you have the following:

A Databricks workspace

An Azure Storage Account (ADLS Gen2)

Necessary access permissions to mount the storage

Required libraries installed in your Databricks cluster

Setup and Execution Flow

1. Mount Azure Data Lake Storage to Databricks

Before running the main project, execute the Mount Storage Account notebook to establish the connection between Databricks and ADLS.
 
2.Perform Basic Checks

Ensure that all required functions and validations are executed by running the Basic Checks Notebook.

3. Run the Main Project File 

Once ADLS is mounted, execute the Main Project File to start the data processing workflow.


</p>
